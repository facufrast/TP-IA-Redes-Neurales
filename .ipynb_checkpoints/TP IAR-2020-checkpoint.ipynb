{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP IAR 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\facu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    \n",
    "    def __init__(self, positionLayer, outputNeuron=False):\n",
    "        self.weights = []\n",
    "        self.inputs = []\n",
    "        self.output = None\n",
    "        \n",
    "        #Pesos actualizados\n",
    "        self.updatedWeights = []\n",
    "        #Determina la neurona de salida\n",
    "        self.outputNeuron = outputNeuron\n",
    "        #Variable para la actualización del Back Propagation\n",
    "        self.delta = None\n",
    "        #Se usa para la actualización del BackPropagation\n",
    "        self.positionLayer = positionLayer \n",
    "        \n",
    "    #Función que sirve para poder guardar una referencia de las otras neuronas, a esta neurona en particular\n",
    "    def actualNeuron(self, neurons):        \n",
    "        self.outputNeurons = neurons\n",
    "    \n",
    "    #Función de activación (Sigmoide)\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    #Asignación de pesos aleatorios, considerando cuántas entradas va a tener la neurona\n",
    "    def initWeights(self, inputNumber):     \n",
    "        for i in range(inputNumber + 1):\n",
    "            self.weights.append(random.uniform(0, 1))\n",
    "        \n",
    "    def predict(self, row):    \n",
    "        #Reseteo de los inputs\n",
    "        self.inputs = []\n",
    "        #Iteración sobre los pesos y los features\n",
    "        activation = 0\n",
    "        for weight, feature in zip(self.weights, row):\n",
    "            self.inputs.append(feature)\n",
    "            activation = activation + weight * feature\n",
    "\n",
    "        self.output = self.sigmoid(activation)\n",
    "        return self.output\n",
    "    \n",
    "    def update_neuron(self):\n",
    "        #Actualización de los pesos de las neuronas (reemplaaza el peso actual por los que se usan durante el algoritmo de backpropagation)\n",
    "        self.weights = []\n",
    "        for newWeight in self.updatedWeights:\n",
    "            self.weights.append(newWeight)\n",
    "    \n",
    "    def calculate_update(self, learningRate, target):\n",
    "        #Cálculo del nuevo peso para la neurona\n",
    "        #Primero se calcula el delta dependiendo si es una neurona oculta o una neurona de salida\n",
    "        if self.outputNeuron:\n",
    "            self.delta = (self.output - target) * self.output * (1 - self.output)\n",
    "        else:\n",
    "            #Cálculo del delta\n",
    "            delta_sum = 0\n",
    "            #Se determina a qué pesos contribuye esta neurona en la capa de salida\n",
    "            curWeightIndex = self.positionLayer \n",
    "            for output_neuron in self.outputNeurons:\n",
    "                delta_sum = delta_sum + (output_neuron.delta * output_neuron.weights[curWeightIndex])\n",
    "\n",
    "            #Actualización del delta\n",
    "            self.delta = delta_sum * self.output * (1 - self.output)\n",
    "            \n",
    "        #Reseteo de los pesos actualizados\n",
    "        self.updatedWeights = []\n",
    "        \n",
    "        #Iteración y actualización sobre cada peso\n",
    "        for curWeight, curInput in zip(self.weights, self.inputs):\n",
    "            gradient = self.delta * curInput\n",
    "            newWeight = curWeight - learningRate * gradient\n",
    "            self.updatedWeights.append(newWeight)\n",
    "            \n",
    "#Permite la conexión entre las neuronas para poder aplicar el algoritmo Back Propagation\n",
    "class Layer():\n",
    "    def __init__(self, neuronsNumber, isOutputLayer = False):\n",
    "        self.isOutputLayer = isOutputLayer\n",
    "        self.neurons = []\n",
    "        #Creación del número de neuronas dado para la capa\n",
    "        for i in range(neuronsNumber):\n",
    "            neuron = Neuron(i,  outputNeuron = isOutputLayer)\n",
    "            self.neurons.append(neuron)\n",
    "    \n",
    "    def attach(self, layer):\n",
    "        #Vinculación de la neurona de esta capa con otra\n",
    "        for inNeuron in self.neurons:\n",
    "            inNeuron.actualNeuron(layer.neurons)\n",
    "            \n",
    "    def init_layer(self, inputNumber):\n",
    "        #Inicialización de los pesos de la neurona en la capa\n",
    "        #Dando el número correcto de inputNumber va a generar el número correcto de pesos\n",
    "        #Se itera sobre cada neurona y se inicializa su peso correspondiente con la capa anterior\n",
    "        for neuron in self.neurons:\n",
    "            neuron.initWeights(inputNumber)\n",
    "    \n",
    "    def predict(self, row):\n",
    "        #Cálculo de la activación de la capa completa\n",
    "        #Vector aumentado\n",
    "        row = np.append(row, 1)\n",
    "        activations = [neuron.predict(row) for neuron in self.neurons]\n",
    "        return activations\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    #Creación del perceptrón multicapa con 2 capas: Una de input, una de perceptrons, y una de salida que hace la clasificación binaria\n",
    "    def __init__(self, learningRate, numIteration):\n",
    "        self.layers = []\n",
    "        self.learningRate = learningRate\n",
    "        self.numIteration = numIteration\n",
    "        \n",
    "    def add_output_layer(self, neuronsNumber):\n",
    "        #Creación de una capa de salida y agregación a la arquitectura\n",
    "        self.layers.insert(0, Layer(neuronsNumber, isOutputLayer = True))\n",
    "    \n",
    "    def add_hidden_layer(self, neuronsNumber):\n",
    "        #Creación de una capa oculta y agregación al frente de la arquitectura\n",
    "        hiddenLayer = Layer(neuronsNumber)\n",
    "        #Agregación de la última capa agregada a esta\n",
    "        hiddenLayer.attach(self.layers[0])\n",
    "        #Agregación de esta capa a la arquitectura\n",
    "        self.layers.insert(0, hiddenLayer)\n",
    "        \n",
    "    def update_layers(self, target):\n",
    "        #Actualización de las capas calculando los nuevos pesos y actualizándolos (todos a la vez) una vez que los nuevos pesos se encontraron\n",
    "        #Iteración sobre cada una de las capas, en orden inverso, para el cálculo de los pesos\n",
    "        for layer in reversed(self.layers):\n",
    "                           \n",
    "            #Cálculo de la actualización\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.calculate_update(self.learningRate, target)  \n",
    "        \n",
    "        #Iteración sobre cada una de las capas para la actualización de los pesos\n",
    "        for layer in self.layers:\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.update_neuron()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_row = len(X)\n",
    "        #Considerando matriz rectangular\n",
    "        num_feature = len(X[0])\n",
    "        \n",
    "        #Inicialización de los pesos en cada una de las capas\n",
    "        self.layers[0].init_layer(num_feature)\n",
    "        \n",
    "        for i in range(1, len(self.layers)):\n",
    "            inputWeights = len(self.layers[i-1].neurons)\n",
    "            self.layers[i].init_layer(inputWeights)\n",
    "\n",
    "        for i in range(self.numIteration):            \n",
    "            r_i = random.randint(0,num_row - 1)\n",
    "            #Se toma una fila aleatoria del dataset\n",
    "            row = X[r_i]\n",
    "            #Se calcula el error con el método 'predict()'\n",
    "            yhat = self.predict(row)\n",
    "            target = y[r_i]\n",
    "            \n",
    "            #Actualización de las capas\n",
    "            self.update_layers(target)\n",
    "            \n",
    "            #Cálculo del error cada 100000 iteraciones\n",
    "            if i % 100000 == 0:\n",
    "                totalError = 0\n",
    "                for r_i in range(num_row):\n",
    "                    row = X[r_i]\n",
    "                    yhat = self.predict(row)\n",
    "                    error = (y[r_i] - yhat)\n",
    "                    totalError = totalError + error ** 2\n",
    "                mean_error = totalError/num_row\n",
    "                print(f\"Iteración {i} con error = {mean_error}\")\n",
    "        \n",
    "    \n",
    "    def predict(self, row):\n",
    "        activations = self.layers[0].predict(row)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            activations = self.layers[i].predict(activations)\n",
    "\n",
    "        outputs = []\n",
    "        for activation in activations:                        \n",
    "            #Considerando si la salida será 0 o 1\n",
    "            if activation >= 0.5:\n",
    "                outputs.append(1.0)\n",
    "            else:\n",
    "                outputs.append(0.0)\n",
    "                           \n",
    "        return outputs[0]\n",
    "\n",
    "    def save_params(self, nombre=\"params\"):\n",
    "        pickle.dump(self.weights, open(nombre + \".pickle\", \"wb\"))\n",
    "        \n",
    "    def load_params(self, nombre=\"params\"):\n",
    "        self.weights = pickle.load(open(nombre + \".pickle\"), \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('X_train.csv', delimiter=',')\n",
    "Y = np.genfromtxt('Y_train.csv', delimiter=',')\n",
    "#Preprocesamiento si es necesario..........."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 0 con error = 0.5\n",
      "Iteración 100000 con error = 0.1555\n",
      "Iteración 200000 con error = 0.0946\n",
      "Iteración 300000 con error = 0.09055\n",
      "Iteración 400000 con error = 0.0897\n",
      "Iteración 500000 con error = 0.0812\n",
      "Iteración 600000 con error = 0.08545\n",
      "Iteración 700000 con error = 0.0769\n",
      "Iteración 800000 con error = 0.08205\n",
      "Iteración 900000 con error = 0.0992\n",
      "Iteración 1000000 con error = 0.0754\n",
      "Iteración 1100000 con error = 0.0868\n",
      "Iteración 1200000 con error = 0.07375\n",
      "Iteración 1300000 con error = 0.07285\n",
      "Iteración 1400000 con error = 0.08475\n",
      "Precisión: 0.90895\n"
     ]
    }
   ],
   "source": [
    "#Inicializando los parámetros\n",
    "clasif = MultiLayerPerceptron(learningRate = 0.15, numIteration = 1500000)\n",
    "#Creación de la arquitectura\n",
    "clasif.add_output_layer(neuronsNumber = 1)\n",
    "clasif.add_hidden_layer(neuronsNumber = 20)\n",
    "#Entrenamiento de la red\n",
    "clasif.fit(X,Y)\n",
    "#res = clasif.predict(X)\n",
    "\n",
    "resultados_train = []\n",
    "for xValue in X:\n",
    "    resultados_train.append(clasif.predict(xValue))\n",
    "res = np.array(resultados_train)\n",
    "\n",
    "#Evaluación del clasificador para los datos de entrenamiento\n",
    "cant_datos = X.shape[0]\n",
    "accuracy = (cant_datos - abs(res - Y).sum())/cant_datos\n",
    "print(\"Precisión:\", accuracy)\n",
    "\n",
    "#Evaluación con datos de test (no cátedra)...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de la cátedra y exportación de resultados y parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.genfromtxt('X_test.csv', delimiter=',')\n",
    "#Preprocesamiento si es necesario...........\n",
    "#res_test = clasif.predict(X_test)\n",
    "\n",
    "resultados = []\n",
    "for xValue in X_test:\n",
    "    resultados.append(clasif.predict(xValue))\n",
    "res_test = np.array(resultados)\n",
    "\n",
    "np.savetxt('Y_test_Grupo_01.csv', res_test, delimiter=',')\n",
    "#clasif.save_params(\"params_Grupo_01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
